{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install music21\n",
    "!pip install matplotlib\n",
    "!pip install pretty_midi\n",
    "from music21 import converter\n",
    "!pip install MIDIUtil\n",
    "#MIDIにする行列の設定は上のセル\n",
    "from midiutil import MIDIFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### U-net\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional\n",
    "!pip install -U segmentation-models-pytorch\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piano_list=np.load('/content/drive/MyDrive/music21/data/piano_list_128_16_2850.npy')\n",
    "quartet_list=np.load('/content/drive/MyDrive/music21/data/quartet_list_128_16_5700.npy')\n",
    "print(len(piano_list))\n",
    "print(len(quartet_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(piano_list[5],cmap='gray')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#128,16の場合\n",
    "train_df = [piano_list[0:1200],quartet_list[0:2400]] #半    データ数\n",
    "val_df =[piano_list[1201:1800],quartet_list[2401:3600]]  #1/4\n",
    "test_df =[piano_list[1801:2400],quartet_list[3601:4800]]  #1/4\n",
    "\n",
    "class Dataset(BaseDataset):  #importしたBaseDatasetクラスを継承してDatasetというクラスを作成\n",
    "  def __init__(\n",
    "      self,\n",
    "      dataset_list,\n",
    "      transform = None,\n",
    "      classes = None,\n",
    "      augmentation = None\n",
    "      ):\n",
    "    self.imgpath_list = dataset_list[0]   #ここにカットしたピアノ譜の小節のリストを入れる、1439ではなくu1438にして、lenメソッドで2で割って曲の数を求めるため　　元の場合は奇数だったため　元のコードは[:-1]\n",
    "    self.labelpath_list = dataset_list[1] #四重奏譜の小節のリストが入る   listはclass Datasetの引数に与えられる   train_df、val_df,test_dfがlistになりそれぞれ2つの要素を持つのでlist[0],list[1]\n",
    "\n",
    "  #get itemのpermuteの確認は大学アカウントのノートブックの行列化の詳細\n",
    "  def __getitem__(self, i):\n",
    "    img_temporal_getitem=[]\n",
    "    #元のはパスから読み込みだがこの場合は行列がすでにあるので途中から\n",
    "    for k in range(2):  #ラベルは4パート\n",
    "          img_index=2*i+k   #i番目の曲のj個目など　　imgpath_list=train_df[0]なのでさらに[0]などとしなくて良い\n",
    "          img = self.imgpath_list[img_index]   #train_df[0]ピアノ譜の行列リストがp1,p2,p1,p2の順で格納されている、それのp1の一小節目\n",
    "          img = torch.from_numpy(img.astype(np.float32)).clone()  #画像をNumPy配列からPyTorchのテンソルに変換し、データタイプを float32 に変更\n",
    "          img_temporal_getitem.append(img)  #imgの形状は(128,16)\n",
    "    #(128,16)のテンソルを2つ結合\n",
    "    img_stack=torch.stack([img_temporal_getitem[0],img_temporal_getitem[1]],dim=2)  #class Datasetでテンソルを2つ結合したものと4つ結合したものを対応させていてこれはチャンネル方向の結合\n",
    "    img_tensor=img_stack.permute(2,0,1)\n",
    "    label_temporal_getitem=[]\n",
    "    for j in range(4):  #ラベルは4パート\n",
    "        label_index=4*i+j   #i番目の曲のj個目など\n",
    "        label=self.labelpath_list[label_index]\n",
    "        label = torch.from_numpy(label.astype(np.float32)).clone()  #ラベルテンソルのデータタイプを float32 に変更\n",
    "        label = label.to(torch.float32)  #ラベルテンソルのデータタイプを float32 に変更\n",
    "        label_temporal_getitem.append(label)  #ここでlabel_temporalgetitem[0]はtensor(128,16,4)\n",
    "\n",
    "    #label_temporalにはtrain_df[1]の全ての行列がテンソル型で格納されている、それぞれtensor(128,16,4)でtrain_df[1]の長さ2878ある     [i]で良いのかは微妙 iはデータセットの長さだが、2878ある\n",
    "    #(128,16)のテンソルを4つ結合\n",
    "    label_stack=torch.stack([label_temporal_getitem[0],label_temporal_getitem[1],label_temporal_getitem[2],label_temporal_getitem[3]],dim=2)\n",
    "    label_tensor=label_stack.permute(2, 0, 1)  #テンソルの次元を変更します。これにより、ラベルテンソルもPyTorchが期待する形式（(チャンネル, 高さ, 幅)）になる\n",
    "    data = {\"img\": img_tensor, \"label\": label_tensor}\n",
    "    return data\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.imgpath_list)//2  #for i, data in enumerate(train_loader): のループ内で i は__len__の返り値をデータセットの長さとして動く\n",
    "                                      #4*iのようにiは曲数になるためimgpathlist(ピアノ譜p1,p2を合わせたリストの長さ)を２で割る   //は切り捨て除算\n",
    "len(train_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataset = Dataset(train_df)\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "val_dataset = Dataset(val_df)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=4,\n",
    "                          shuffle=False)\n",
    "test_dataset = Dataset(test_df)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                          batch_size=1,\n",
    "                          num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):  #in_channelsは入力チャンネル数、middle_channelsは中間チャンネル数、out_channelsは出力チャンネル数\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, middle_channels, kernel_size = 3, padding=\"same\") #padding=\"same\"で入出力のテンソルの形状を一致させる、strideはデフォルトで1\n",
    "        self.bn1 = nn.BatchNorm2d(middle_channels)\n",
    "        self.rl = nn.SiLU()  #活性化関数\n",
    "        self.conv2 = nn.Conv2d(middle_channels, out_channels, kernel_size = 3, padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.residual_conv=nn.Conv2d(in_channels,out_channels,kernel_size=1,bias=False)#1*1の畳み込みで形状を変えずにチャンネル数を増やす　特徴量次元数を畳み込み後のxとresidueで揃える\n",
    "\n",
    "    def forward(self, x):\n",
    "        #residue=self.residual_conv(x)     #x=(32,2,128,16)\n",
    "        x = self.conv1(x)  #(32,64,128,16)\n",
    "        x = self.bn1(x)   #(32,64,128,16)\n",
    "        x = self.rl(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.rl(x)\n",
    "        return x\n",
    "\n",
    "class UpConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size = 2, padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn2(x)\n",
    "        return x\n",
    "\n",
    "#Unetの全層\n",
    "class UNet_2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.TCB1 = TwoConvBlock(2, 64, 64)  #TwoConvBlockは畳み込み、バッチ正規化、活性化関数を２つ繋げたブロック　入力は2チャンネル、1つ目のconvで出力が64チャンネル、2つ目のconvで64チャンネルになるということ\n",
    "        self.TCB2 = TwoConvBlock(64, 128, 128)\n",
    "        self.TCB3 = TwoConvBlock(128, 256, 256)\n",
    "        self.TCB4 = TwoConvBlock(256, 512, 512)\n",
    "        self.TCB5 = TwoConvBlock(512, 1024, 1024)\n",
    "        self.TCB6 = TwoConvBlock(1024, 512, 512)\n",
    "        self.TCB7 = TwoConvBlock(512, 256, 256)\n",
    "        self.TCB8 = TwoConvBlock(256, 128, 128)\n",
    "        self.TCB9 = TwoConvBlock(128, 64, 64)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride = 2)\n",
    "        self.UC1 = UpConv(1024, 512)\n",
    "        self.UC2 = UpConv(512, 256)\n",
    "        self.UC3 = UpConv(256, 128)\n",
    "        self.UC4= UpConv(128, 64)\n",
    "        self.conv1 = nn.Conv2d(64, 4, kernel_size = 1)\n",
    "        self.dropout=nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.TCB1(x) #縦横2ずつ小さくなる  (126,14)\n",
    "        x1 = x\n",
    "        x = self.maxpool(x) #マックスプーリングでノイズ除去、位置変化に頑健 形状が半分になる  (63,7)\n",
    "        x = self.TCB2(x)  #(61,5)\n",
    "        x2 = x\n",
    "        x = self.maxpool(x) #(30,2)\n",
    "        x = self.TCB3(x)\n",
    "        x3 = x\n",
    "        x = self.maxpool(x)\n",
    "        x = self.TCB4(x)\n",
    "        x4 = x                 #512チャンネル\n",
    "        x = self.maxpool(x)\n",
    "        x = self.TCB5(x)\n",
    "        #ここからUnetのデコーダー\n",
    "        x = self.UC1(x)\n",
    "        x=self.dropout(x)\n",
    "        x = torch.cat([x4, x], dim = 1)#Unetのスキップ接続　図の通りコピーを結合\n",
    "        x = self.TCB6(x)\n",
    "        x = self.UC2(x)\n",
    "        x=self.dropout(x)\n",
    "        x = torch.cat([x3, x], dim = 1)\n",
    "        x = self.TCB7(x)\n",
    "        x = self.UC3(x)\n",
    "        x = torch.cat([x2, x], dim = 1)\n",
    "        x = self.TCB8(x)\n",
    "        x = self.UC4(x)\n",
    "        if x1.size(3) !=x.size(3):  #128の次元が一致していない場合\n",
    "          x=torch.nn.functional.interpolate(x,size=(x1.size(2),x1.size(3)),mode='bilinear',align_corners=True)\n",
    "        x = torch.cat([x1, x], dim = 1)\n",
    "        x = self.TCB9(x)\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights=torch.tensor([100,100,100,100],device=device)\n",
    "pos_weight=torch.tensor([100],device=device)\n",
    "unet = UNet_2D().to(device)\n",
    "optimizer = optim.Adam(unet.parameters(), lr=1e-6)\n",
    "history = {\"train_loss\": []} #各エポックごとのtrain_loss\n",
    "n = 0\n",
    "m = 0\n",
    "#初期化\n",
    "for epoch in range(61):  #trainは1438あり2パートなので約700セット\n",
    "  train_loss = 0\n",
    "  val_loss = 0\n",
    "  unet.train() #unetを訓練モードにする\n",
    "  print('tpの初期化')\n",
    "  for i, data in enumerate(train_loader):  #トレーニングデータローダーからバッチごとにデータを取得し、それをループ、trainloderは辞書形式 iは何番目のバッチかを示す\n",
    "    inputs,labels = data[\"img\"].to(device), data[\"label\"].to(device) #データローダーから入力画像とラベルを取り出し、それらを計算を行うデバイス（CPUまたはGPU）に移動\n",
    "    optimizer.zero_grad()  #最適化関数の勾配を初期化\n",
    "    outputs = unet(inputs) #モデルに入力データを与えて、出力を計算\n",
    "    loss_function=nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    loss=loss_function(outputs,labels)\n",
    "    #損失関数元のコードのを使う場合\n",
    "    loss.backward()  #誤差逆伝播法でネットワークの重みに関する損失関数の勾配を求める　どのように各重みを調整すれば損失を減少させることができるかが分かる\n",
    "    optimizer.step()  #計算された勾配を使用してモデルのパラメータを更新\n",
    "    train_loss += loss.item()  #現在のバッチにおける損失のスカラー値を返す　train_loss +=は、この損失値をtrain_loss変数に加算　これは、エポック全体を通じて処理されたすべてのバッチの損失を合計するため　エポックの終わりに、この合計損失をバッチの総数で割ることで、エポック全体の平均損失が計算され、モデルの訓練中のパフォーマンスを評価するための指標になる\n",
    "    history[\"train_loss\"].append(loss.item())  #historyという辞書のtrain_lossというキーにloss.item()を追加\n",
    "    n += 1\n",
    "\n",
    "  unet.eval()\n",
    "  with torch.no_grad():\n",
    "    tp=0\n",
    "    fn=0\n",
    "    fp=0\n",
    "    tn=0\n",
    "    total_score=0\n",
    "    for i, data in enumerate(val_loader):\n",
    "      inputs, labels = data[\"img\"].to(device), data[\"label\"].to(device)\n",
    "      outputs = unet(inputs)\n",
    "      loss_function=nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "      loss=loss_function(outputs,labels)\n",
    "      #softmaxの場合　合計1にするので閾値0.5ではなく各列　各時間に対応　の最大値\n",
    "      outputs=torch.softmax(outputs,dim=3)\n",
    "      max_indices = np.argmax(outputs.cpu(), axis=3)\n",
    "      # 各行の最大値だけ1にして、それ以外を0にする\n",
    "      new_array = np.zeros_like(outputs.cpu())\n",
    "\n",
    "      for i in range(outputs.shape[0]):\n",
    "        for j in range(outputs.shape[1]):\n",
    "          for k in range(outputs.shape[2]):\n",
    "              new_array[i,j,k,max_indices[i,j,k]]=1\n",
    "      outputs=new_array\n",
    "      val_loss += loss.item()\n",
    "      m += 1\n",
    "      if i % (len(val_df[0])//BATCH_SIZE) == len(val_df[0])//BATCH_SIZE - 1:   # バッチの個数でバッチ番号iを割ったものが　バッチの個数-1 になった時　最後のバッチの時\n",
    "        print(f\"epoch:{epoch+1}  index:{i+1}  val_loss:{val_loss/m:.5f}\")\n",
    "        m = 0\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "\n",
    "    #評価指標の計算 for i,data の外側なのでエポックごとのTPなど tpの初期化はエポックごとではないので全体のtpが求まる\n",
    "    outputs_eval_list=[]\n",
    "    print(type(outputs))\n",
    "    for l in range(outputs.shape[0]):  #バッチサイズ\n",
    "        for m in range(4):  #チャンネル数\n",
    "            outputs_eval_list=outputs[l][m].tolist()  #outputsに\n",
    "            labels_eval_list=labels[l][m].tolist()\n",
    "\n",
    "            for j in range(16):\n",
    "              for k in range(128):   #128_64での変更点\n",
    "                if outputs_eval_list[j][k]==1 and labels_eval_list[j][k]==1:\n",
    "                  tp+=1\n",
    "                elif outputs_eval_list[j][k]==1 and labels_eval_list[j][k]==0:\n",
    "                  fp+=1\n",
    "                elif outputs_eval_list[j][k]==0 and labels_eval_list[j][k]==1:\n",
    "                  fn+=1\n",
    "                elif outputs_eval_list[j][k]==0 and labels_eval_list[j][k]==0:\n",
    "                  tn+=1\n",
    "    #評価指標の計算続き\n",
    "    if tp+fn>0:\n",
    "      precision=tp/(tp+fn)\n",
    "    else:\n",
    "      precision=0\n",
    "    if tp+fp>0:\n",
    "      recall=tp/(tp+fp)\n",
    "    else:\n",
    "      recall=0\n",
    "    if 2*tp+fp+fn>0:\n",
    "      f1_score=2*tp/(2*tp+fp+fn)\n",
    "    else:\n",
    "      f1_score=0\n",
    "    print(\"epoch\",epoch)\n",
    "    print(\"precision\",precision)\n",
    "    print(\"Recall\",recall)\n",
    "    print(\"F1_Score\",f1_score)\n",
    "    if (precision+recall+f1_score)>total_score:\n",
    "      total_score=recall+f1_score  #recallとf1scoreが重要なため\n",
    "      print(epoch,\"epoch \",\"precision\",precision,\"recall\",recall,\"f1_score\",f1_score)\n",
    "  torch.save(unet.state_dict(), f\"./train_{epoch+1}.pth\")#インデントの位置からepochごとに重み情報などをstate_dictに保存\n",
    "  print(\"epoch\",epoch)\n",
    "print(\"finish training\")\n",
    "\n",
    "plt.plot(history[\"train_loss\"]) #曲線のグラフ\n",
    "plt.xlabel('batch')\n",
    "plt.ylabel('loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(15,8))\n",
    "ax[0].imshow(data[\"img\"][0,:,:,:][0])   #軸表示は逆だったが最初の行列化の時点で上下は正しくなっているはずなのでここでは変更なし\n",
    "ax[0].set_title(\"ピアノ譜右手\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].imshow(data[\"img\"][0,:,:,:][1])\n",
    "ax[1].set_yticks(range(128,0,-10))\n",
    "ax[1].set_title(\"ピアノ譜左手\")\n",
    "ax[1].axis(\"off\")\n",
    "plt.figure()\n",
    "\n",
    "classes = [\"第1パート\",\"第2パート\",\"第3パート\",\"第4パート\"]\n",
    "fig, ax = plt.subplots(2, 4, figsize=(15,8))\n",
    "\n",
    "for i in range(2):\n",
    "  for j, cl in enumerate(classes):   #enumerate(classes)で各要素jとインデックスclを取得\n",
    "    if i == 0:\n",
    "      output_score=[]\n",
    "      pred_transpose=pred[0,:,:,j].to('cpu').detach().numpy().copy()  #predの1チャンネル目0を指定するのはそもそも1チャンネル目は1次元しかないため、テンソルをcpuメモリに移動、.detachで勾配情報を取り除く、numpyにしてコピーを作成\n",
    "      print(type(pred_transpose))  #ndarray\n",
    "      print(\"pred_transpose\",pred_transpose.shape)  #(128,16)\n",
    "      print(pred_transpose[31:73].shape)   #(42,16)\n",
    "\n",
    "      #音域設定\n",
    "      if j==0 or j==1:  #第1パート\n",
    "         pred_transpose=pred_transpose[31:73].T\n",
    "         pred_transpose_index=(np.argmax(pred_transpose,axis=1))  #axis=1は列方向になるのでaxis=0\n",
    "         pred_transpose_index+=31\n",
    "\n",
    "      elif j==2:\n",
    "         pred_transpose=pred_transpose[43:80].T\n",
    "         pred_transpose_index=(np.argmax(pred_transpose,axis=1))  #axis=1は列方向になるのでaxis=0\n",
    "         pred_transpose_index+=43\n",
    "\n",
    "      elif j==3:\n",
    "         pred_transpose=pred_transpose[55:92].T\n",
    "         pred_transpose_index=(np.argmax(pred_transpose,axis=1))  #axis=1は列方向になるのでaxis=0\n",
    "         pred_transpose_index+=55\n",
    "\n",
    "      b=np.zeros((16,128))\n",
    "      for k in range(16):    #全て0にした行列(16,128)の指定したインデックスの場所だけ1にする,b[k]は128個の要素がある1次元配列(128,)は(128,1)とは異なる\n",
    "        b[k][pred_transpose_index[k]]=1       #(16,128)の行ごとに指定のインデックスの部分を1にする b[k]は各行(128,)\n",
    "        output_score.append(b[k].tolist())\n",
    "      #出力の行列をMIDIにする時用いるリスト\n",
    "      #各リストはそれぞれ予測のパート1~4\n",
    "      if j ==0:\n",
    "        output_midi_list=[output_score]\n",
    "      else:\n",
    "        output_midi_list.append(output_score)\n",
    "\n",
    "      output_score=np.array(output_score)  #listからndarray\n",
    "      output_score=torch.from_numpy(output_score.astype(np.float32)).clone()  #ndarrayからtensorにする\n",
    "      output_score=output_score.T  #(16,128)から元の形状(128,16)にする\n",
    "      print(\"output_scoreの形状\",output_score.shape)\n",
    "      ax[i,j].imshow(output_score)   #iは0,j=1~4   pred[0,全ての行と列,1~4チャンネル]\n",
    "      ax[i,j].axis(\"off\")\n",
    "      ax[i,j].set_title(f\"pred_{cl}\")\n",
    "    else:\n",
    "      ax[i,j].imshow(data[\"label\"][0,j,:,:])\n",
    "      ax[i,j].axis(\"off\")\n",
    "      ax[i,j].set_title(f\"label_{cl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIDIファイル化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIDIファイルに変換することで音声として聞くことが可能になる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ここでMIDIファイルにする行列を設定  output_midi_list[3].T  など\n",
    "#predはoutput_midi_listに4つ格納されている\n",
    "a=data[\"img\"][0,:,:,:][0]\n",
    "a=torch.from_numpy(a.astype(np.float32)).clone()\n",
    "\n",
    "# バイナリ行列の例\n",
    "matrix = a\n",
    "# MIDIファイルを初期化\n",
    "midi_file = MIDIFile(1)  # トラック数1\n",
    "track = 0   # トラック0\n",
    "time = 0    # 開始時間\n",
    "midi_file.addTrackName(track, time, \"Track\")\n",
    "midi_file.addTempo(track, time, 60)  # テンポ120 BPM\n",
    "# 行列からMIDIノートを生成\n",
    "for row in range(matrix.shape[0]):\n",
    "    note = row  # MIDIノートナンバー\n",
    "    duration = 0  # 音符の持続時間\n",
    "    for col in range(matrix.shape[1]):\n",
    "        if matrix[row, col] == 1:\n",
    "            duration += 1  # 音符の持続時間を延長\n",
    "        elif duration > 0:\n",
    "            # 音符の終わりに到達\n",
    "            midi_file.addNote(track, 0, note, time + col - duration, duration, 100)\n",
    "            duration = 0\n",
    "    #行の要素の全てが1の場合、行の最後でもfor文の中のifブロックが実行されるのでelifが実行されず保存がないためforループの外で行の全てが1の場合を保存\n",
    "    if duration > 0:\n",
    "         print(\"activated\")\n",
    "         midi_file.addNote(track, 0, note, time + matrix.shape[1] - duration, duration, 100) #forループ外なのでcolではなくmatrix.shape[1]-1\n",
    "\n",
    "# MIDIファイルを保存\n",
    "with open(\"output.mid\", \"wb\") as output_file:\n",
    "    midi_file.writeFile(output_file)\n",
    "    \n",
    "from google.colab import files\n",
    "files.download('output.mid')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
